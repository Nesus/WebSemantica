{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA-RDF Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "from rdflib.namespace import RDF, FOAF\n",
    "\n",
    "import rdflib\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N7d86a68da07b43ceb41d0f56df644646 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se crea un grafo y luego cargamos los valores de prueba\n",
    "g = Graph()\n",
    "g.parse(\"sampleBig.ttl\", format=\"turtle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def de_uri(uri):\n",
    "    \"\"\"\n",
    "        Función que toma una URI y la convierte en un string.\n",
    "    \"\"\"\n",
    "    return uri.split(\"/\")[-1].replace(\"_\",\" \").split(\"#\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "#Se buscan todas las personas\n",
    "for s in g.subjects(RDF.type, FOAF.Person):\n",
    "    subject = de_uri(s)\n",
    "    \n",
    "    #Se comienza el documento con el nombre del recurso\n",
    "    document = subject\n",
    "    \n",
    "    #Se buscan los triples asociados a ese recurso y se van agregando al documento\n",
    "    for p,o in g.predicate_objects(s):\n",
    "        \n",
    "        prop = de_uri(p)\n",
    "        if not(prop == u'birthDate' or prop == u'deathDate'):\n",
    "            obj = de_uri(o)\n",
    "            document += \" \" + prop + \" \" + obj + \" \"\n",
    "    \n",
    "    #Se agregan a una lista de documentos\n",
    "    documents.append(document)\n",
    "    \n",
    "    \n",
    "    #Guardamos un documento de prueba\n",
    "    if subject == \"August Horch\":\n",
    "        test_document = document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'August Horch', u'description', u'German engineer and automobile pioneer')\n",
      "(u'August Horch', u'deathDate', u'1951-02-03')\n",
      "(u'August Horch', u'givenName', u'August')\n",
      "(u'August Horch', u'birthDate', u'1868-10-12')\n",
      "(u'August Horch', u'birthPlace', u'Winningen')\n",
      "(u'August Horch', u'surname', u'Horch')\n",
      "(u'August Horch', u'deathPlace', u'Bavaria')\n",
      "(u'August Horch', u'name', u'August Horch')\n",
      "(u'August Horch', u'birthPlace', u'Rhine Province')\n",
      "(u'August Horch', u'deathPlace', u'M\\xfcnchberg')\n",
      "(u'August Horch', u'type', u'Person')\n",
      "August Horch description German engineer and automobile pioneer  givenName August  birthPlace Winningen  surname Horch  deathPlace Bavaria  name August Horch  birthPlace Rhine Province  deathPlace Münchberg  type Person \n"
     ]
    }
   ],
   "source": [
    "#Un ejemplo de como se ve el documento\n",
    "august = rdflib.term.URIRef(u'http://dbpedia.org/resource/August_Horch')\n",
    "for s,p,o in g.triples((august, None, None)):\n",
    "    subject = de_uri(s)\n",
    "    prop = de_uri(p)\n",
    "    obj = de_uri(o)\n",
    "    print (subject,prop,obj)\n",
    "print test_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de caracteristicas\n",
    "Primero se necesita transformar los documentos a una lista de frecuencias de palabras (bag of words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se crea un CountVectorizer que analiza los documentos, y busca las palabras más representativas\n",
    "vectorizer = CountVectorizer(max_df=0.5, min_df=0.01,\n",
    "                                max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2366, 110)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se transforman los documentos en una matriz de caracteristicas\n",
    "X = vectorizer.fit_transform(documents)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'actor',\n",
       " u'actress',\n",
       " u'american',\n",
       " u'ancient',\n",
       " u'and',\n",
       " u'angeles',\n",
       " u'architect',\n",
       " u'artist',\n",
       " u'astronomer',\n",
       " u'australian',\n",
       " u'austria',\n",
       " u'author',\n",
       " u'british',\n",
       " u'brooklyn',\n",
       " u'california',\n",
       " u'charles',\n",
       " u'chemist',\n",
       " u'chicago',\n",
       " u'christian',\n",
       " u'city',\n",
       " u'composer',\n",
       " u'computer',\n",
       " u'county',\n",
       " u'david',\n",
       " u'de',\n",
       " u'director',\n",
       " u'emperor',\n",
       " u'empire',\n",
       " u'engineer',\n",
       " u'england',\n",
       " u'english',\n",
       " u'fiction',\n",
       " u'film',\n",
       " u'founder',\n",
       " u'france',\n",
       " u'french',\n",
       " u'general',\n",
       " u'george',\n",
       " u'german',\n",
       " u'germany',\n",
       " u'greek',\n",
       " u'henry',\n",
       " u'historian',\n",
       " u'holy',\n",
       " u'hungary',\n",
       " u'ii',\n",
       " u'illinois',\n",
       " u'in',\n",
       " u'italian',\n",
       " u'italy',\n",
       " u'james',\n",
       " u'japanese',\n",
       " u'john',\n",
       " u'king',\n",
       " u'kingdom',\n",
       " u'london',\n",
       " u'los',\n",
       " u'massachusetts',\n",
       " u'mathematician',\n",
       " u'musician',\n",
       " u'new',\n",
       " u'novelist',\n",
       " u'of',\n",
       " u'painter',\n",
       " u'papal',\n",
       " u'paris',\n",
       " u'paul',\n",
       " u'pennsylvania',\n",
       " u'philosopher',\n",
       " u'physicist',\n",
       " u'player',\n",
       " u'playwright',\n",
       " u'poet',\n",
       " u'poland',\n",
       " u'politician',\n",
       " u'pope',\n",
       " u'president',\n",
       " u'producer',\n",
       " u'province',\n",
       " u'republic',\n",
       " u'robert',\n",
       " u'roman',\n",
       " u'rome',\n",
       " u'russian',\n",
       " u'saint',\n",
       " u'san',\n",
       " u'science',\n",
       " u'scientist',\n",
       " u'scotland',\n",
       " u'scottish',\n",
       " u'screenwriter',\n",
       " u'short',\n",
       " u'singer',\n",
       " u'songwriter',\n",
       " u'south',\n",
       " u'soviet',\n",
       " u'state',\n",
       " u'states',\n",
       " u'story',\n",
       " u'texas',\n",
       " u'the',\n",
       " u'theologian',\n",
       " u'thomas',\n",
       " u'union',\n",
       " u'united',\n",
       " u'vienna',\n",
       " u'west',\n",
       " u'william',\n",
       " u'writer',\n",
       " u'york']"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA\n",
    "Luego de transformar los documentos a vectores de ocurrencia, se entrena el modelo LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_jobs=1, n_topics=10, perp_tol=0.1, random_state=None,\n",
       "             topic_word_prior=None, total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de entrenar el modelo, vemos las n primeras palabras de cada tópico, con esto podemos asignarle un nombre a cada tópico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "john england and london philosopher mathematician kingdom artist british english ancient greek of astronomer poet playwright hungary german italy writer\n",
      "Topic #1:\n",
      "new york american city and author scientist san brooklyn computer actor massachusetts california playwright painter state states united politician mathematician\n",
      "Topic #2:\n",
      "writer thomas david english south american fiction and science county australian author london composer producer england singer of california novelist\n",
      "Topic #3:\n",
      "pope roman empire rome italy saint charles papal henry states holy state province player kingdom and republic christian of composer\n",
      "Topic #4:\n",
      "california american director musician film russian massachusetts and actor illinois producer los historian angeles west composer chicago screenwriter scotland novelist\n",
      "Topic #5:\n",
      "william singer american actor ii and physicist actress poland engineer chemist texas architect songwriter british in vienna english mathematician the\n",
      "Topic #6:\n",
      "united states de george pennsylvania american president theologian general and astronomer politician christian state of angeles los south french west\n",
      "Topic #7:\n",
      "of the german and italian germany king republic hungary austria vienna composer in founder christian scotland politician painter state saint\n",
      "Topic #8:\n",
      "robert novelist poet paul and soviet writer union american story short scottish playwright scotland screenwriter state founder republic british texas\n",
      "Topic #9:\n",
      "emperor james french france british politician japanese paris roman painter artist and mathematician american italy rome philosopher film holy united\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 20\n",
    "print_top_words(lda, feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos entregarle nuevos documentos ya transformados en vectores de frecuencia al modelo LDA y ver a qué temas corresponde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1       ,  2.10000034,  2.09999966, ...,  0.1       ,\n",
       "         0.1       ,  0.1       ],\n",
       "       [ 0.1       ,  0.1       ,  0.1       , ...,  0.10003642,\n",
       "         0.1       ,  0.1       ],\n",
       "       [ 1.70799038,  0.1000073 ,  1.29977914, ...,  0.10000979,\n",
       "         0.10001902,  0.10000069],\n",
       "       ..., \n",
       "       [ 1.09998241,  1.10059784,  0.1       , ...,  0.1       ,\n",
       "         0.1       ,  0.10001607],\n",
       "       [ 0.1       ,  1.51290653,  0.10000476, ...,  0.1       ,\n",
       "         0.10000299,  0.1       ],\n",
       "       [ 3.78901791,  3.40497885,  0.10000716, ...,  0.10000925,\n",
       "         0.10000709,  1.10589967]])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Parece que el dataset no es muy bueno porque los temas que encuentra no son muy representativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
